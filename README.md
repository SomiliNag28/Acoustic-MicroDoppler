[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![GitHub Repo Size](https://img.shields.io/github/repo-size/SomiliNag28/Acoustic-MicroDoppler)

# Privacy-Preserving Indoor Human Activity Sensing Using Acoustic Micro-Doppler

An end-to-end **ultrasonic sensing system** that detects **human presence and motion** using **Doppler physics** and **machine learning**, without capturing **speech, identity, visual data**.

This project demostrates how a simple speaker and microphone can function as a **privacy-safe indoor radar** by transmitting as ultrasonic probe (~18kHz), analyzing its reflections and extracting **micro-doppler signatures** generated by human motion.

---

## ▨ Overview

Traditional indoor sensing relies on cameras or microphones that capture sensitive personal information.  
This system replaces those with a **physics-based sensing approach**:

Speaker → Room → Human Motion → Microphone → Doppler → Machine Learning → Presence

Only **motion-induced frequency shifts** are used.  
No voice, no words, no faces, no identity.

---

## ▨ Core Principle

When an ultrasonic tone of frequency \( f_0 \) reflects off a moving person, the returned signal is shifted by:

\[
f_d = \frac{2 v}{c} f_0
\]

Where:
- \( v \) is the velocity of body motion  
- \( c \) is the speed of sound  
- \( f_d \) is the Doppler shift  

These small frequency changes create **micro-Doppler patterns** that uniquely encode human movement such as walking, hand motion, or breathing.

---

## ▨ What This System Can Detect

- Human presence  
- Body motion  
- Activity intensity  

## ▨ What This System Cannot Capture

- Speech  
- Words  
- Identity  
- Facial appearance  

This makes it suitable for **privacy-preserving smart environments**.

---

## ▨ System Architecture

1. **Ultrasonic Transmission**  
   A continuous 18 kHz tone is emitted into the room.

2. **Acoustic Reflection**  
   The signal reflects off walls and moving human body parts.

3. **Signal Capture**  
   A microphone records the combined direct and reflected waves.

4. **Doppler Extraction**  
   Short-Time Fourier Transform isolates frequency shifts around 18 kHz.

5. **Clutter Cancellation**  
   Stationary reflections (walls, speaker path) are removed to isolate motion.

6. **Feature Engineering**  
   Physical motion descriptors are computed:
   - Total motion energy  
   - Doppler bandwidth  
   - Temporal activity  
   - Velocity variance  

7. **Machine Learning**  
   A Support Vector Machine classifies:
   - Empty room  
   - Human present

---

## ▨ Project Structure

 Acoustic-MicroDoppler/  
├── data/  
│   ├── raw_recordings  
│   └── processed  
├── signals/  
│   ├── probe_signal.wav  
├── src/  
│   ├── generate_probe.py  
│   ├── doppler_extract.py  
│   ├── features.py       
│   ├── build_dataset.py  
│   ├── train_ml.py   
│   └── visualize.py  
├── results/   
│   ├── plots/  
│   ├── models/    
├── README.md   
└── report.pdf

---

##  ▨ Technologies Used

| Component                | Technology                      |
| -------------------------------- | -------------------------------------- |
| Signal Proccessing   | NumPy, SciPy, Librosa   |
| Machine Learning     | scikit-learn                        |
| Visualization              | Matplotlib                         |
| Audio I/O                    | soundfile                           |
|Model Storage           | joblib                                  |

---

## ▨ Applications

Smart homes without cameras
Elderly monitoring with privacy
Gesture and activity sensing
Occupancy detection
Secure indoor analytics

---

## ▨ Academic Relevance

This project follows the same pipeline used in:

**Radar micro-Doppler systems**

**WiFi sensing**

**RF human activity recognition**

but implemented using acoustic ultrasound, making it low-cost, safe, and deployable on consumer devices.


